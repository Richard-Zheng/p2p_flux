{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5050a58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#from diffusers import FluxPipeline\n",
    "from pipeline_p2p_flux import FluxPrompt2PromptPipeline as FluxPipeline\n",
    "from pipeline_p2p_flux import AttentionStore\n",
    "\n",
    "pipe = FluxPipeline.from_pretrained(\"/home/frain/Documents/FLUX.1-dev\", torch_dtype=torch.bfloat16)\n",
    "pipe.enable_sequential_cpu_offload() #save some VRAM by offloading the model to CPU. Remove this if you have enough GPU power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2e0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inference_steps = 20\n",
    "controller = AttentionStore(\n",
    "    len(pipe.transformer.transformer_blocks),\n",
    "    len(pipe.transformer.single_transformer_blocks),\n",
    "    num_inference_steps,\n",
    ")\n",
    "controller.register_attention_control(pipe)\n",
    "\n",
    "prompt = \"An astronaut pinpointing a flag that says hello world on the surface of Mars, digital art\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=3.5,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef3c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from typing import Optional, Union, Tuple, List, Callable, Dict\n",
    "import cv2\n",
    "\n",
    "def text_under_image(image: np.ndarray, text: str, text_color: Tuple[int, int, int] = (0, 0, 0)):\n",
    "    h, w, c = image.shape\n",
    "    offset = int(h * .2)\n",
    "    img = np.ones((h + offset, w, c), dtype=np.uint8) * 255\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    # font = ImageFont.truetype(\"/usr/share/fonts/truetype/noto/NotoMono-Regular.ttf\", font_size)\n",
    "    img[:h] = image\n",
    "    textsize = cv2.getTextSize(text, font, 1, 2)[0]\n",
    "    text_x, text_y = (w - textsize[0]) // 2, h + offset - textsize[1] // 2\n",
    "    cv2.putText(img, text, (text_x, text_y ), font, 1, text_color, 2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def view_images(images, num_rows=1, offset_ratio=0.02):\n",
    "    if type(images) is list:\n",
    "        num_empty = len(images) % num_rows\n",
    "    elif images.ndim == 4:\n",
    "        num_empty = images.shape[0] % num_rows\n",
    "    else:\n",
    "        images = [images]\n",
    "        num_empty = 0\n",
    "\n",
    "    empty_images = np.ones(images[0].shape, dtype=np.uint8) * 255\n",
    "    images = [image.astype(np.uint8) for image in images] + [empty_images] * num_empty\n",
    "    num_items = len(images)\n",
    "\n",
    "    h, w, c = images[0].shape\n",
    "    offset = int(h * offset_ratio)\n",
    "    num_cols = num_items // num_rows\n",
    "    image_ = np.ones((h * num_rows + offset * (num_rows - 1),\n",
    "                      w * num_cols + offset * (num_cols - 1), 3), dtype=np.uint8) * 255\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            image_[i * (h + offset): i * (h + offset) + h:, j * (w + offset): j * (w + offset) + w] = images[\n",
    "                i * num_cols + j]\n",
    "\n",
    "    pil_img = Image.fromarray(image_)\n",
    "    display(pil_img)\n",
    "\n",
    "def show_cross_attention(attention_maps, tokens, decoder):\n",
    "    images = []\n",
    "    for i in range(len(tokens)):\n",
    "        #ipdb.set_trace()\n",
    "        image = attention_maps[i, :].reshape(64, 64)\n",
    "        image = 255 * image / image.max()\n",
    "        image = image.unsqueeze(-1).expand(*image.shape, 3)\n",
    "        image = image.numpy().astype(np.uint8)\n",
    "        image = np.array(Image.fromarray(image).resize((256, 256)))\n",
    "        image = text_under_image(image, decoder(int(tokens[i])))\n",
    "        images.append(image)\n",
    "    view_images(np.stack(images, axis=0))\n",
    "\n",
    "show_cross_attention(controller.attention_store.to(dtype=torch.float32).cpu().float(), tokens, pipe.tokenizer_2.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12729ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# release memory\n",
    "del pipe.controller\n",
    "del pipe\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
